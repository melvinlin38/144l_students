---
title: "DADA2"
author: "Melvin Lin"
date: "11/7/2020"
output: github_document
---

# Install and Load DADA2 and ShortRead from Bioconductor 
```{r}
#install.packages("devtools")
#library("devtools")
#devtools::install_github("benjjneb/dada2", ref="v1.16")
```

```{r}
#library("devtools")
#devtools::install_github("benjjneb/dada2")
```

```{r}
library(dada2)
library(ShortRead)
# install.packages("dplyr")
# install.packages("tidyverse")
library(tidyverse)
```

```{r}
path <- "~/GITHUB/144l_students/Input_Data/week5/ACIDD_Remin_fastq/"

#store the names of the forward and rev files as lists

fnFs <- list.files(path, pattern = "_R1_001.fastq", full.names = TRUE)
fnRs <- list.files(path, pattern = "_R2_001.fastq", full.names = TRUE)
```

# Retrieve orientation of primers
The primers targeted the V4 region and are known 514F-Y and 806RB primers 

```{r}
#store the forward and reverse primers
FWD = "GTGYCAGCMGCCGCGGTAA"
REV = "GGACTACNVGGGTWTCTAAT"

# now store all orientations of forward and reverse primers
allOrients <- function(primer) {
  # The Biostrings work w/ DNAstring objects rather than character vectors
  require(Biostrings)
  dna <- DNAString(primer)
  orients <- c(Forward = dna, Complement = complement(dna), Reverse = reverse(dna),
               RevComp = reverseComplement(dna))
  return(sapply(orients, toString))
}

#store the fwd and reverse orientations separately 
FWD.orients <- allOrients(FWD)
REV.orients <- allOrients(REV)

#view the orientations of the primers
FWD.orients
REV.orients
```

# Search for Primers

```{r}
primerHits <- function(primer, fn) {
  # Counts number of reads in which the primer is found
  nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
  return(sum(nhits > 0))
}

rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs[[1]]),
      FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnFs[[1]]),
      REV.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs[[1]]),
      REV.ReverseReads = sapply(FWD.orients, primerHits, fn = fnFs[[1]]))

```

At this point a 4x4 table is returned. If all numbers are 0, then you don't have primers in your sequence. If they have numbers, use cutadept to remove the primers. 

# Inspect read quality profiles

You should look at at least some of the quality profiles to assess the quality of the sequencing rn.

## Forward reads

```{r fig.height=10, fig.width=12}
plotQualityProfile((fnFs[1:12]))
```

## Reverse reads

```{r fig.height=10, fig.width=12}
plotQualityProfile(fnRs[1:12])
```

# Filtering and Trimming

```{r}
#Get the sample names
#define the basename of the FnFs as the first part of each fastQ file name until "_L"
#apply this to all samples
sample.names <- sapply(strsplit(basename(fnFs), "_L"), `[`, 1)
sample.names
#create a "filtered" folder in the working directory as a place to put all new filtered fastQ files
filt_path <- file.path(path,"filtered")
#add the appropriate designation string to any new files made that will be put into the "filtered" folder
filtFs <- file.path(filt_path, paste0(sample.names, "_F_filt.fastq"))
filtRs <- file.path(filt_path, paste0(sample.names, "_R_filt.fastq"))
```

```{r}
out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen = c(240,150), maxN = 0, maxEE = c(2,2), truncQ = 2, rm.phix = TRUE, compress = TRUE)
#look at the output. this tells you how many reads were removed
out
```

#Learn the error rates

```{r}
errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)
```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height =10, fig.width = 12, fig.align = "center", warning = FALSE}
plotErrors(errF, nominalQ = TRUE)

```

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height =10, fig.width = 12, fig.align = "center", warning = FALSE}
plotErrors(errR, nominalQ = TRUE)

```

#Dereplication

Dada2 combines all identical sequences into one unique sequence, keeping track of the number of identical sequences

```{r}
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
# Name the derep-class objects by the sample names
names(derepFs) <- sample.names
names(derepRs) <- sample.names
```
# Infer the sequence variants
Apply the core dada2 sample inference algorithm to the dereplicated data.

Infer the sequence variants in each sample, taking out the sequence variants that have excessive error rates.

```{r}
dadaFs <- dada(derepFs, err = errF, multithread = TRUE)
dadaRs <- dada(derepRs, err = errR, multithread = TRUE)
```

merge the overlapping reads -> this will also decrease the number of sequence variants.

```{r}
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE, trimOverhang = T)
```

inspect the merged data frame from the first sample. This will output a table. the numbers in the forward and reverse columns tell where those sequences are in the dadaFs and dadaRs files. nmatch is how many bases matched. we uniformly trimmed the amplicons so they should all be the same. 

```{r}
head(mergers[[1]])
```

save the unassigned merged reads
```{r}
saveRDS(mergers, "~/GITHUB/144l_students/Output_Data/week5/dada_merged.rds")
saveRDS(mergers, "~/GITHUB/144l_students/Input_Data/week6/dada_merged.rds")
```

construct a sequence table of our samples that is analagous to the "OTU table" produced by classical methods

```{r}
seqtab <- makeSequenceTable(mergers)
dim(seqtab) #samples by unique sequences
```

check the distribution of the sequence lengths

```{r}
table(nchar(getSequences(seqtab)))
```

# Remove the Chimeras

in PCR, two or more biological sequences can attach to each other and then polymerase builds a non-biological sequence. Weird. These are are artifacts that need to be removed

```{r}
seqtab.nochim <- removeBimeraDenovo(seqtab, verbose = TRUE)
dim(seqtab.nochim)
```

check the proportion of sequences that are not chimeras

```{r}
sum(seqtab.nochim)/sum(seqtab)
```

# Assign taxonomy using a reference database

here we are referencing the Silva database

```{r}
taxa <- assignTaxonomy(seqtab.nochim, "~/GITHUB/144l_students/Input_Data/week5/Reference_Database/silva_nr_v138_train_set.fa", multithread = TRUE)
```

Create a table out of the taxa data (one with the sequences and assignments, one with just all the taxa)

these are the tables you want to save

```{r}
saveRDS(t(seqtab.nochim), "~/GITHUB/144l_students/Output_Data/week5/seqtab-nochimtaxa123.rds")
saveRDS(taxa, "~/GITHUB/144l_students/Output_Data/week5/taxa123.rds")

saveRDS(t(seqtab.nochim), "~/GITHUB/144l_students/Input_Data/week6/seqtab-nochimtaxa123.rds")
saveRDS(taxa, "~/GITHUB/144l_students/Input_Data/week6/taxa123.rds")
```

